{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897394ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "897394ee",
    "outputId": "5ad2d645-82b2-43d6-ea4e-bcc3f4be6156"
   },
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbed2e0",
   "metadata": {
    "id": "bcbed2e0"
   },
   "source": [
    "# Make sure the version of anaconda is the latest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63095a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad63095a",
    "outputId": "62159a36-b8ee-4f15-a96e-a0babacdb6f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn  # importing sklearn\n",
    "print(sklearn.__version__)  # printing sklearn version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46355d5",
   "metadata": {
    "id": "d46355d5"
   },
   "source": [
    "## Importing the relevent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce7b57",
   "metadata": {
    "id": "76ce7b57"
   },
   "outputs": [],
   "source": [
    "import nltk # importing natural language processing toolkit \n",
    "from nltk.corpus import stopwords  # helps remove stopwords\n",
    "from nltk.stem import WordNetLemmatizer # lemmantizes words\n",
    "from nltk.corpus import wordnet  # will be used to replace words with there antonyms\n",
    "from nltk.stem import PorterStemmer  # stemms words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j57mgL-7aaWx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j57mgL-7aaWx",
    "outputId": "d60f5b53-bf08-44ab-9404-5fa134555b0e"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BDHDJpaVaafR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDHDJpaVaafR",
    "outputId": "e3aba136-c257-4ebc-f9fe-cf0bbb8fd5b2"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_3Fo21_Baapo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3Fo21_Baapo",
    "outputId": "23508f98-a8e7-4dab-c49e-5a32dd798bd6"
   },
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad22c05",
   "metadata": {
    "id": "d46355d5"
   },
   "source": [
    "## Importing the relevent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trMS5PEvOWXs",
   "metadata": {
    "id": "trMS5PEvOWXs"
   },
   "outputs": [],
   "source": [
    "import numpy as np  # Allows us to work with arrays.\n",
    "import pandas as pd  # importing pandasâ€™ library for use. Allows us to import data set and manipulate it.\n",
    "import string  # import string library function\n",
    "import re  # works with Regular Expressions\n",
    "import pickle  # allows to open and save to files\n",
    "from nltk.tokenize import word_tokenize  # tokenizes sentences.\n",
    "\n",
    "import seaborn as sns  # Allows to polt beautiful plots.\n",
    "import matplotlib.pyplot as plt  # Allows working with plots.\n",
    "from mpl_toolkits import mplot3d  # plotting 3d plots\n",
    "\n",
    "from sklearn.compose import ColumnTransformer  # helps with encoding.\n",
    "from sklearn.preprocessing import OneHotEncoder  # Does onehotencode.\n",
    "from sklearn.preprocessing import LabelEncoder   # Does 1 and 0 encoding.\n",
    "from sklearn.model_selection import train_test_split  # Splits dataset into test set and traning set. \n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, Normalizer  # Perform the feature scaling.\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, multilabel_confusion_matrix  # creates a \n",
    "from sklearn.naive_bayes import GaussianNB  # applies  naive_bayes gaussianNB.\n",
    "from sklearn.tree import DecisionTreeClassifier  # applies  decision tree classification model.                                                                            # confusion matrix  # creates a confusion matrix\n",
    "    \n",
    "from sklearn.metrics import accuracy_score  # Returns accury score of a model.\n",
    "from collections import Counter  # Allows the counting the items in an iterable list.\n",
    "\n",
    "from sklearn.model_selection import cross_val_score  # performs cross validation. Helps in model selection.\n",
    "from sklearn.model_selection import GridSearchCV  # helps select the best hyper parameters\n",
    "# from imblearn.over_sampling import RandomOverSampler  # Uses over sampling techniques to Sample the data correctly.\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, precision_score, roc_auc_score, f1_score \n",
    "                                                                                 # Allows the usage of a classification report\n",
    "    \n",
    "from sklearn.metrics import precision_recall_fscore_support  # gives precison, recall, f1 score, and support\n",
    "from sklearn.model_selection import RandomizedSearchCV  # performs randomized search cv\n",
    "\n",
    "\n",
    "import warnings  # allows to ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")  # ignores warnings\n",
    "\n",
    "#%matplotlib inline  # helps in showing plots on the browser.### Importing the relevent libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c5c32",
   "metadata": {
    "id": "024c5c32"
   },
   "source": [
    "## Importing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985866e5",
   "metadata": {
    "id": "985866e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DataFrame = pd.read_csv(\"FinalBalancedDataset.csv\")  # opens csv files and assighns them to a variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4d2088",
   "metadata": {
    "id": "7e4d2088"
   },
   "source": [
    "# Checking the data from the dataframe before pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb046731",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bb046731",
    "outputId": "2e9a7def-f935-4cf5-deb5-eb9e6c643ac5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DataFrame.head(5)  # Taking a look at the dataframe the first elements of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0ea9d1",
   "metadata": {
    "id": "cb0ea9d1"
   },
   "outputs": [],
   "source": [
    "DataFrame = DataFrame.drop('Unnamed: 0', 1)  # column is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b27895",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8b27895",
    "outputId": "4ce4ad84-15d3-4704-fff4-9e6670116e79",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DataFrame.info()  # checking Basic information on the dataframe being procesed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da515d3",
   "metadata": {
    "id": "7da515d3"
   },
   "source": [
    "## 1. Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45095b25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45095b25",
    "outputId": "0da3714e-e772-413b-bcd9-ed73f86a4f7a"
   },
   "outputs": [],
   "source": [
    "DataFrame.shape  # The Entries and the columns of the dataframe are viewed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6b358d",
   "metadata": {
    "id": "2a6b358d"
   },
   "source": [
    "## Dealing with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0a58b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "d9e0a58b",
    "outputId": "d32d5531-fa02-4a40-ba04-ccf421da39f3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(DataFrame.isnull())  # shows null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4d2ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82c4d2ab",
    "outputId": "8ef53a34-2724-4943-c645-105d2d0026cd"
   },
   "outputs": [],
   "source": [
    "DataFrame.isnull().sum()  # Checking the dataframe for null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6q-NI2y8glQO",
   "metadata": {
    "id": "6q-NI2y8glQO"
   },
   "source": [
    "## Dealing with duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RO1T8yxpgaGY",
   "metadata": {
    "id": "RO1T8yxpgaGY"
   },
   "outputs": [],
   "source": [
    "DataFrame.drop_duplicates(inplace = True)  # checks for duplicates and removes them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mf6FfQPdgaGZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mf6FfQPdgaGZ",
    "outputId": "5fde994f-c925-43ba-bace-92e9aeb5fa35"
   },
   "outputs": [],
   "source": [
    "print(DataFrame.pivot_table(columns=['Toxicity'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90eeccb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f90eeccb",
    "outputId": "b75350a3-41b4-4f25-cb36-77b4b694edd8"
   },
   "outputs": [],
   "source": [
    "DataFrame.info()  # checking basic information on dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add14eb6",
   "metadata": {
    "id": "add14eb6"
   },
   "source": [
    "## Balancing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd74bca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edd74bca",
    "outputId": "b0016484-963d-4946-8887-21a45046ec15"
   },
   "outputs": [],
   "source": [
    "print(DataFrame.pivot_table(columns=['Toxicity'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e03781",
   "metadata": {
    "id": "24e03781"
   },
   "outputs": [],
   "source": [
    "zero = str(round(100 * (30389/56745),2)) + \"%\"   # percentage of the value is checked from label column.\n",
    "one  = str(round(100 * (23924/56745),2)) + \"%\"  # percentage of the value is checked from label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439cf7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a439cf7e",
    "outputId": "fb7d73e0-6671-4140-8d59-3ba6fb4ae893"
   },
   "outputs": [],
   "source": [
    "print(\"0 is represented \", zero, \"\\n1 is represented \", one)\n",
    "# percentage of the value is printed of label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03341d32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03341d32",
    "outputId": "d94ae2ea-7dd6-4fa5-a984-5481844957ad"
   },
   "outputs": [],
   "source": [
    "30389 - 23924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1929e3",
   "metadata": {
    "id": "ad1929e3"
   },
   "outputs": [],
   "source": [
    "row_to_remove = np.random.RandomState(1).choice(DataFrame[DataFrame['Toxicity']==0].index,size=6465,replace=False)\n",
    "DataFrame = DataFrame.drop(row_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96954824",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96954824",
    "outputId": "aeed9a15-e851-4d9e-de9d-f9b92a9bca39"
   },
   "outputs": [],
   "source": [
    "print(DataFrame.pivot_table(columns=['Toxicity'], aggfunc='size'))  # counts duplicates in the selected dataframe column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbedef1",
   "metadata": {
    "id": "1cbedef1"
   },
   "source": [
    "# Reseting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc5c5b",
   "metadata": {
    "id": "99dc5c5b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DataFrame.reset_index(drop=True, inplace=True)  # reseting index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0cbc36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8b0cbc36",
    "outputId": "fc47d064-aed6-4620-e89f-04e76b4ad6d2"
   },
   "outputs": [],
   "source": [
    "DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gxDFeIanLTHl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxDFeIanLTHl",
    "outputId": "69843ae2-53ce-4d13-9f9d-c9cf91d27d5d"
   },
   "outputs": [],
   "source": [
    "DataFrame.info()  # checking basic information on dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2-_PV8GAnsRy",
   "metadata": {
    "id": "2-_PV8GAnsRy"
   },
   "source": [
    "## removing non word symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zgWZUnAelWFa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zgWZUnAelWFa",
    "outputId": "659ebc10-f340-408b-e618-85c470da92b4"
   },
   "outputs": [],
   "source": [
    "DataFrame['tweet'] = DataFrame['tweet'].str.replace('[^\\w\\s]','')\n",
    "DataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kNsk9YqFAXIf",
   "metadata": {
    "id": "kNsk9YqFAXIf"
   },
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hDiVpjXFAVpp",
   "metadata": {
    "id": "hDiVpjXFAVpp"
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()  # creating the instance of the object.\n",
    "DataFrame.Toxicity = le.fit_transform(DataFrame.Toxicity)  # label encoing the require dcolumn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F72wEqBeHXWs",
   "metadata": {
    "id": "F72wEqBeHXWs"
   },
   "source": [
    "## Spliting X and y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W1HZyHbJHV-c",
   "metadata": {
    "id": "W1HZyHbJHV-c"
   },
   "outputs": [],
   "source": [
    "X = DataFrame.iloc[:, -1].values  # selecting the values for the X variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JFumALt6HqvO",
   "metadata": {
    "id": "JFumALt6HqvO"
   },
   "outputs": [],
   "source": [
    "y = DataFrame.iloc[:, :-1].values # selecting the values for the Y variable. # done using .to_numpy and not \n",
    "                                                       # .iloc as .to_numpy creates a horizontal bar while .iloc creates a \n",
    "                                                       # horizontal bar which will not alighn with the x values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4NISLP6ZJFsE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NISLP6ZJFsE",
    "outputId": "d1b4340b-a523-469a-dc5d-a15b03cd6d5e"
   },
   "outputs": [],
   "source": [
    "print(\"X \", X, \"y \", y)  # priting arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O9vsQQVKFsIB",
   "metadata": {
    "id": "O9vsQQVKFsIB"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "TJl_zy9PlTVT",
   "metadata": {
    "id": "TJl_zy9PlTVT"
   },
   "source": [
    "## Removing punctuations, special character and converting text to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdy2zzD4KzUo",
   "metadata": {
    "id": "cdy2zzD4KzUo"
   },
   "outputs": [],
   "source": [
    "no_punctuation_and_no_stop_words = []\n",
    "for i in range(0,len(X)):\n",
    "  # removing non word symbols\n",
    "  data = re.sub(r'\\W',' ', str(X[i]))\n",
    "  # converting the data to lower case\n",
    "  data = data.lower()\n",
    "  # removing single characters\n",
    "  data = re.sub(r'\\s+[a-z]\\s+', ' ', data)\n",
    "  # removing single characters at the start of a sentence\n",
    "  data = re.sub(r'^[a-z]\\s+',' ',data)\n",
    "  #replacing everything other than alphabets with a space\n",
    "  data =re.sub(\"[^a-zA-Z]\",\" \",data)\n",
    "  # removing extra spaces\n",
    "  data = re.sub(r'\\s+',' ', data)\n",
    "  no_punctuation_and_no_stop_words.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j_2g4K9fNg1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j_2g4K9fNg1d",
    "outputId": "34adb342-3d8b-4a19-e292-7e4e2108641d"
   },
   "outputs": [],
   "source": [
    "no_punctuation_and_no_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TsrtsfgsmDwj",
   "metadata": {
    "id": "TsrtsfgsmDwj"
   },
   "source": [
    "## Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VFFKFOoIQr8j",
   "metadata": {
    "id": "VFFKFOoIQr8j"
   },
   "outputs": [],
   "source": [
    "# removing stop words\n",
    "tokenized_words = [word_tokenize(str(i)) for i in no_punctuation_and_no_stop_words]\n",
    "stopset = set(stopwords.words('english'))\n",
    "clean_model = []\n",
    "for m in range(len(tokenized_words)):\n",
    "      stop_m = [i for i in tokenized_words[m] if i not in stopset]\n",
    "      clean_model.append(' '.join(stop_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vqha1ygwr-3x",
   "metadata": {
    "id": "Vqha1ygwr-3x"
   },
   "source": [
    "## Clean sentences model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OKQoeBTdUNFF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKQoeBTdUNFF",
    "outputId": "1caab67c-8804-49e7-e617-611cc5230335"
   },
   "outputs": [],
   "source": [
    "clean_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nvATdjTB-UZP",
   "metadata": {
    "id": "nvATdjTB-UZP"
   },
   "source": [
    "## Replacing words starting with not with there antonym (Will do after to see if further improvements can be made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Co2Lb3Hi-UZY",
   "metadata": {
    "id": "Co2Lb3Hi-UZY"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tokenized_words = [word_tokenize(str(i)) for i in clean_model]\n",
    "temp_word = \"\"\n",
    "model_after_antonyms_replacement = []\n",
    "for m in range(len(tokenized_words)):\n",
    "   final_word = []\n",
    "   for n in range(len(tokenized_words[m])):\n",
    "     antonyms = []\n",
    "     # replacing not with not_\n",
    "     if tokenized_words[m][n] == \"not\":\n",
    "       temp_word = \"not_\"\n",
    "     # replacing word starting with not_ with its antonym\n",
    "     elif temp_word == \"not_\":\n",
    "       for sys in wordnet.synsets(tokenized_words[m][n]):  \n",
    "         for s in sys.lemmas():\n",
    "           for a in s.antonyms(): \n",
    "             antonyms.append(a.name())\n",
    "       # adding antonym word to original word\n",
    "       if len(antonyms) >= 1:\n",
    "           tokenized_words[m][n] = antonyms[0]\n",
    "       # adding not_ to original word\n",
    "       else:\n",
    "         if tokenized_words[m][n] != tokenized_words[m][-1]:\n",
    "           tokenized_words[m][n+1] = temp_word + tokenized_words[m][n+1]\n",
    "       temp_word = \"\"\n",
    "     if tokenized_words[m][n] != \"not\":\n",
    "           final_word.append(tokenized_words[m][n])\n",
    "   model_after_antonyms_replacement.append(' '.join(final_word))  \n",
    "   \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lhQP_6Lv_cm6",
   "metadata": {
    "id": "lhQP_6Lv_cm6"
   },
   "outputs": [],
   "source": [
    "clean_model = model_after_antonyms_replacement\n",
    "clean_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gs6mmxypa8dT",
   "metadata": {
    "id": "gs6mmxypa8dT"
   },
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yXgxLXntlpMz",
   "metadata": {
    "id": "yXgxLXntlpMz"
   },
   "outputs": [],
   "source": [
    "tokenized_words = [word_tokenize(str(i)) for i in clean_model]\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lematized_model = []\n",
    "for m in range(len(tokenized_words)):\n",
    "      lema_m = [lemmatizer.lemmatize(word) for word in tokenized_words[m]]\n",
    "      lematized_model.append(' '.join(lema_m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VMOhzTEesydl",
   "metadata": {
    "id": "VMOhzTEesydl"
   },
   "source": [
    "## Lemmatized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "avQzpjUQnqIg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avQzpjUQnqIg",
    "outputId": "96fcb723-bb92-4be7-dd58-5786be6c6d52"
   },
   "outputs": [],
   "source": [
    "lematized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SYlJl6Nk5n5T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SYlJl6Nk5n5T",
    "outputId": "13f79be1-3411-471e-b4ee-5d487c358229"
   },
   "outputs": [],
   "source": [
    "print(lematized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hk5IR2H66WUF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hk5IR2H66WUF",
    "outputId": "eaa9bccb-6ce6-4207-d67e-1ea1331e1b10"
   },
   "outputs": [],
   "source": [
    "type(lematized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0pdsBkVDQo-Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0pdsBkVDQo-Q",
    "outputId": "f9abd84b-eb8f-47a5-bec2-de0576e6f528"
   },
   "outputs": [],
   "source": [
    "len(lematized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TdaVW6hcQtUN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdaVW6hcQtUN",
    "outputId": "0ad72408-717f-43a7-d204-eb1c1994dc03"
   },
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in y for item in sublist]\n",
    "print(len(flat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDf = pd.DataFrame(\n",
    "    {   'Labels': flat_list,\n",
    "        'Tweets': lematized_model\n",
    "     \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e235fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(47848 / 2)\n",
    "print(23924 / 4)\n",
    "print(5981+5981)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df6db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = NewDf[NewDf['Labels']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811190f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = NewDf[NewDf['Labels']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676c449",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a4860",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = d1.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d281440",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b2de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf2 = d2.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb67c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a015f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf1 = pd.concat([newdf2, newdf1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c16178",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ba7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf1.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf1 = finaldf1.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d219e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c63a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = sum(pd.Series(' '.join(finaldf1['Tweets']).split()).value_counts())\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3uyxs20fg-T7",
   "metadata": {
    "id": "3uyxs20fg-T7"
   },
   "source": [
    "## Removing the rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mFPrpQrvj2b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFPrpQrvj2b3",
    "outputId": "9ac5506f-875f-4282-e407-27a44909591f"
   },
   "outputs": [],
   "source": [
    "# freq = pd.Series(' '.join(finaldf1['Tweets']).split()).value_counts()[-15:]\n",
    "# freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hRfS1OoZnFXW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hRfS1OoZnFXW",
    "outputId": "af4b14cc-b4fd-4ab1-cff6-175595b9bdde"
   },
   "outputs": [],
   "source": [
    "# finaldf1['Tweets'] = finaldf1['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "# finaldf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f6b536",
   "metadata": {
    "id": "3uyxs20fg-T7"
   },
   "source": [
    "## Removing the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc2ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq = pd.Series(' '.join(finaldf1['Tweets']).split()).value_counts()[:55]\n",
    "#freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finaldf1['Tweets'] = finaldf1['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "#finaldf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3uyxs20fg-T7",
   "metadata": {
    "id": "3uyxs20fg-T7"
   },
   "source": [
    "## Removing words by occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "# split words into lists\n",
    "v = finaldf1['Tweets'].str.split().tolist() # [s.split() for s in df['Col2'].tolist()]\n",
    "# compute global word frequency\n",
    "c = Counter(chain.from_iterable(v))\n",
    "# filter, join, and re-assign\n",
    "finaldf1['Tweets'] = [' '.join([j for j in i if c[j] > 6]) for i in v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f811352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = sum(pd.Series(' '.join(finaldf1['Tweets']).split()).value_counts())\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e9fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e11cf08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7488bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf1 = finaldf1.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5384ac",
   "metadata": {
    "id": "F72wEqBeHXWs"
   },
   "source": [
    "## Spliting X and y variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07b3cc",
   "metadata": {
    "id": "W1HZyHbJHV-c"
   },
   "outputs": [],
   "source": [
    "X = finaldf1.iloc[:, -1].values  # selecting the values for the X variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eecd4e",
   "metadata": {
    "id": "JFumALt6HqvO"
   },
   "outputs": [],
   "source": [
    "y = finaldf1.iloc[:, :-1].values # selecting the values for the Y variable. # done using .to_numpy and not \n",
    "                                                       # .iloc as .to_numpy creates a horizontal bar while .iloc creates a \n",
    "                                                       # horizontal bar which will not alighn with the x values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f3b1d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NISLP6ZJFsE",
    "outputId": "d1b4340b-a523-469a-dc5d-a15b03cd6d5e"
   },
   "outputs": [],
   "source": [
    "print(\"X \", X, \"y \", y)  # priting arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80107c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb13c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c anaconda gensim\n",
    "#!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0571854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from gensim.models import Word2Vec, KeyedVectors\n",
    "import nltk\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "embeddingsSize=100\n",
    "model = Word2Vec(sentences=X_train, vector_size=embeddingsSize, window=5, min_count=1, workers=2)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de10fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifier_function(model, X_train, y_train,X_test,y_test, title):  # function takes the name of the \n",
    "    \n",
    "    \n",
    "  \"\"\"\n",
    "    The Classifier_function Checks, predicted/actual results , checks testing and traning scores, \n",
    "    Checks Actual values classified correctly and wrongly Checks accuracy, precision, recall,  f1 \n",
    "    scores and area under the curve.\n",
    "    It plots a confusion matix with accuracy, precision, recall,  f1 scores given.\n",
    "    \n",
    "    The first parameter is model the model to evaluate.\n",
    "    \n",
    "    The secound parameter X_train is the variable contaning training datas features.\n",
    "    \n",
    "    The third parameter y_train is the variable contaning training datas label.\n",
    "    \n",
    "    The fourth parameter X_test is the variable contaning testing datas features.\n",
    "    \n",
    "    The fifth parameter y_test is the variable contaning testing datas label.\n",
    "    \n",
    "    The sixth parameter is the string which will be used as the title for the confusion matrix.\n",
    "    \n",
    "    The Classifier_function function returns the train_accuracy,test_accuracy , precision, recall,\n",
    "    f1_score and Area_under_the_curve of a given model. \n",
    "    \n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "                                                               # model used, the x and y traning and testing sets.\n",
    "  model.fit(X_train, y_train)  # Building the k-nearest neighbors classification model.\n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "  y_test_p = model.predict(X_test)  # Predicted results.\n",
    "  print(\"  results\\npred-Actual\")  # printing predicted and real values.\n",
    "  print(np.concatenate((y_test_p.reshape(len(y_test_p),1),y_test.reshape(len(y_test),1)),1))  # Predicted results and \n",
    "                                                                                       #  real results in a np array.\n",
    "   \n",
    "\n",
    "  train_accuracy = round(model.score(X_train,y_train),2 ) * 100  # Getting traing accuracy multipling it by 100 after \n",
    "                                                                # rounding it by 2 to get a score between 0 to 100\n",
    "  test_accuracy = round(model.score(X_test,y_test),2) * 100  # Getting testing accuracy multipling it by 100 after \n",
    "                                                                # rounding it by 2 to get a score between 0 to 100\n",
    "\n",
    "  print(\"Model train accuracy: \", train_accuracy, \"%\")  # printing the model accurcy. \n",
    "  print(\"Model test accuracy: \", test_accuracy, \"%\")  # printing the model accurcy. \n",
    "\n",
    "\n",
    "  print(\"\\n\\n\")  # printing a new line.\n",
    "  # getting Accuracy or recall or precision or specificity\n",
    "  y_test_pred = model.predict(X_test)  # predicted results\n",
    "  \n",
    "  cReport = classification_report(y_test,y_test_pred)  # creating a Classification report\n",
    "  print(cReport)  # creating a Classification report\n",
    "  \n",
    "  cm = confusion_matrix(y_test, y_test_p)  # creating the confusion matrix\n",
    "  cm2 = multilabel_confusion_matrix(y_test, y_test_pred)  # creating a mutable confusion matrix\n",
    "\n",
    "\n",
    "  precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_test_pred)  # getting the precision,\n",
    "                                                                                          # recall and f1score for later use.\n",
    "  accuracy  = round(np.trace(cm) / float(np.sum(cm)), 2) * 100  # getting aaccuracy and multipling it by 100 after \n",
    "                                                                # rounding it by 2 to get a score between 0 to 100.\n",
    "  precision = round(np.mean(precision),2) * 100  # multipling precision variables mean by 100 after rounding it by\n",
    "                                                #  2 to get a score between 0 to 100.\n",
    "  recall = round(np.mean(recall),2) * 100  # multipling recall variables mean by 100 after rounding it by 2 to \n",
    "                                           # get a score between 0 to 100.\n",
    "  f1_score = round(np.mean(f1_score),2) * 100  # multipling f1_score variables mean by 100 after rounding \n",
    "                                               # it by 2 to get a score between 0 to 100.\n",
    "\n",
    "  lable_list = []  # creating a empty list\n",
    "\n",
    "  for i in range(len(cm)):  # looping in the range of the length of the confusion matrix.\n",
    "    for j in range(len(cm)):  # looping in the range of the length of the confusion matrix.\n",
    "        if j == i:  # if the value of j is equal to the value of i.\n",
    "            # the below code appends the Actual Values Classified correctly to the variable lable_list.\n",
    "            lable_list.append(\"Actual \"+ str(i) +\"\\n\" + \"calssified as \"+ str(j) +\"\\n\" + str(cm[i][j]) + \"\\n\"+ \\\n",
    "                              str(round(cm[i][j]/np.sum(cm),2)) + \" %\")\n",
    "\n",
    "        else:   # otherwise\n",
    "            #  the below function appends the actual values classified wrongly to the variable lable list.\n",
    "            lable_list.append(\"Actual \"+ str(i) +\"\\n\" + \"calssified as \"+ str(j) + \"\\n\"  + str(cm[i][j]) + \"\\n\"+ \\\n",
    "                              str(round(cm[i][j]/np.sum(cm),2)) + \" %\")\n",
    "\n",
    "            \n",
    "  lable_list = np.asarray(lable_list).reshape(len(cm),len(cm))  # resahping the label list as a numpy array to be \n",
    "                                                                # used in plotting the confusion matrix\n",
    "  \n",
    "  #  the variable function will be will be used to display the results of the evaluation to the confusion matrix.\n",
    "  total_score = (\"Accuracy:   \" + str(accuracy) +\" %\" + \"\\nPrecison:    \"  + str(precision)  +\" %\" + \"\\nRecall:        \" +\\\n",
    "                 str(recall)  +\" %\" + \"\\nF1 score:    \"  + str(f1_score) +\" %\") \n",
    "\n",
    "\n",
    "  # Below is the code used to plot the confusion matrix.\n",
    "  plt.figure()  # sets the size of the matrix\n",
    "  disp = sns.heatmap(cm, annot=lable_list, fmt='', cmap='Blues')  # displays the results of the actual values \n",
    "                                                                 #  classified wrongly and correctly.                       \n",
    "  disp.plot()  # displaying data in plot\n",
    "  plt.title(title, fontsize=25)  # adding a title to plot\n",
    "  plt.ylabel('True label', fontsize=20)  # adding a y axis to the plot.\n",
    "  plt.xlabel('Predicted label' +\"\\n\\nScores\\n\" +total_score, fontsize=20)  # adding a x axis to the plot\n",
    "  plt.show()  # showing the plot\n",
    "\n",
    "\n",
    "  plt.figure()\n",
    "  fpr, tpr, _ =  metrics.roc_curve(y_test,  y_test_pred)\n",
    "  auc = metrics.roc_auc_score(y_test, y_test_pred)\n",
    "  plt.plot(fpr,tpr,label= title +\", auc=\"+str(auc))\n",
    "  plt.xlabel('False Positive Rate')\n",
    "  plt.ylabel('True Positive Rate')\n",
    "  plt.legend(loc=4)\n",
    "  plt.show()\n",
    "    \n",
    "  print(\"Area under the curve: \", auc) \n",
    "    \n",
    "  result_list = train_accuracy,test_accuracy , precision, recall, f1_score,auc  # returning the results\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "  return result_list  # returns the results from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be88ca26",
   "metadata": {},
   "source": [
    "# Sub function to preform Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06972bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "solver_list = ['svd', 'lsqr', 'eigen']\n",
    "shrinkage_list = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "n_components_list = [None, 1, 2, 5, 8, 13, 21, 34, 55]\n",
    "store_covariance_list =  [True, False]\n",
    "tol_list = [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]\n",
    "\n",
    "para_grid = dict(shrinkage = shrinkage_list, solver = solver_list, n_components = n_components_list, store_covariance = store_covariance_list, tol = tol_list)  # adding the above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd20d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rand_search_fun(typeofmodelandprams, dict_prams,crossval, X, y):  # Function takes in the model type, \n",
    "                                                            # number of crossvalidation sand X and y values as hyperparameters.\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    The function rand_search_fun performs random search on a model. It prints the best results and \n",
    "    the hyperparametrs used to obtain those results and then it plots those results.\n",
    "    \n",
    "    The first parameter typeofmodelandprams is the type of model used on which random search is performed on.\n",
    "    \n",
    "    The secound parameter dict_prams is a dictinory of hyperparameters to be used in the random search.\n",
    "    \n",
    "    The third parameter crossval is the number of cross validations to be performed.\n",
    "    \n",
    "    The fourth parameter X is the features.\n",
    "    \n",
    "    The fifth parameter y is the labels.\n",
    "    \n",
    "    \n",
    "    The function rand_search_fun returns the results of the random search.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    model = typeofmodelandprams  # creating an instance of the object.\n",
    "    parameters = [dict_prams]  # hyper parameters for the random search \n",
    "    rand_search = RandomizedSearchCV(\n",
    "                           model,\n",
    "        #estimator = model,  # model\n",
    "                           #param_distributions = parameters,  # hyper paramaters \n",
    "                           parameters,\n",
    "                           scoring = 'f1_micro',  # score measurement\n",
    "                           cv = crossval, # number of cross validations \n",
    "                           n_jobs = -1, # selecting all possible paramaters to go through to get the best model possible \n",
    "                           return_train_score=False, # train score is false as it can be computationaly \n",
    "                                                  # expensive. without storing the traning score the grd search is fater\n",
    "                           n_iter=10,  # setting the number of iterations\n",
    "                           random_state=5)  \n",
    "    rand_search.fit(X, y)  # applying the search on our model.\n",
    "    #print(pd.DataFrame(rand_search.cv_results_)[[\"mean_test_score\",\"params\"]])\n",
    "\n",
    "    best_accuracy = rand_search.best_score_  # the best accuracy \n",
    "    best_parameters = rand_search.best_params_  # the best paramaters that gave the best accurecy\n",
    "    print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))  # printing best accuracy\n",
    "    print(\"Best Parameters:\", best_parameters)  # printing the best parameters\n",
    "    \n",
    "\n",
    "\n",
    "    return rand_search  # return random search value.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b9d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    " def bagofwordsgrid(n,n1):\n",
    "        \n",
    "  model = TfidfVectorizer(ngram_range=(n,n1)) \n",
    "  cv_X = model.fit_transform(X).toarray()\n",
    "    \n",
    "  #cv = CountVectorizer(ngram_range=(n,n1))\n",
    "  #cv_X = cv.fit_transform(X).toarray()\n",
    "  \n",
    "  rand_search_fun(LinearDiscriminantAnalysis(), para_grid, 5, cv_X, y) \n",
    "                                                                                                       # lists in a dictinary.\n",
    "  #grid_search = Grid_search_fun(DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_leaf_nodes = None, \\\n",
    "                                    #min_weight_fraction_leaf = 0.0,criterion = 'entropy', \\\n",
    "                                    #max_features = None), para_grid, 5, cv_X, y)  # Using the grid search gunction with\n",
    "\n",
    "# DecisionTreeClassifier()\n",
    "# GaussianNB()     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L-uZDsald4HE",
   "metadata": {
    "id": "L-uZDsald4HE"
   },
   "source": [
    "# N-gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VEdMi995Ovcw",
   "metadata": {
    "id": "VEdMi995Ovcw"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  # bag of words model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55879d",
   "metadata": {
    "id": "L-uZDsald4HE"
   },
   "source": [
    "## Bag of words gird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagofwordsgrid(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9828c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import OneHotEncoder  # Does onehotencode.\n",
    "enc = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f7e99b",
   "metadata": {
    "id": "L-uZDsald4HE"
   },
   "source": [
    "## Bag of words function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XOwQn6C3dxn1",
   "metadata": {
    "id": "XOwQn6C3dxn1"
   },
   "outputs": [],
   "source": [
    " def bagofwords(n,n1):\n",
    "        \n",
    "  cv = CountVectorizer(ngram_range=(n,n1))\n",
    "  cv_X = cv.fit_transform(X).toarray()\n",
    "  \n",
    "  cv_X_train, cv_X_test, cv_y_train, cv_y_test = train_test_split(cv_X, y, test_size = 0.2, random_state = 1)\n",
    "  # test_size = 0.2               # splitting the data into 80 and 20 percent between the training and test set           \n",
    "                                              # to get the best results.                                                           \n",
    "  # random_state = 1         # resetting the  random seed\n",
    "  # print the lenghth of both test and train set to see if there equally split.\n",
    "  print(\"The length of X_train is \",len(cv_X_train), \" and the length of y_train is \", len(cv_y_train))  \n",
    "  print(\"The length of X_test is \",len(cv_X_test), \" and the length of y_test is \", len(cv_y_test))\n",
    "  Classifier_function(BernoulliNB(), cv_X_train, cv_y_train, cv_X_test, cv_y_test, \"Bernoulli NB\")\n",
    "\n",
    "# fit_intercept = 'True',average = 'False'\n",
    "\n",
    "# make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "# make_pipeline(StandardScaler(), LinearSVC(random_state=0, tol=1e-5))\n",
    "\n",
    "# ExtraTreesClassifier()\n",
    "# MultinomialNB()\n",
    "# LinearDiscriminantAnalysis()\n",
    "#BernoulliNB()\n",
    "                                                                                                       # lists in a dictinary.\n",
    "  #grid_search = Grid_search_fun(DecisionTreeClassifier(min_samples_leaf = 1, min_samples_split = 2, max_leaf_nodes = None, \\\n",
    "                                    #min_weight_fraction_leaf = 0.0,criterion = 'entropy', \\\n",
    "                                    #max_features = None), para_grid, 5, cv_X, y)  # Using the grid search gunction with \n",
    "# DecisionTreeClassifier()\n",
    "# GaussianNB()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge scikit-multiflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3720b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U scikit-multiflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33703ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rMA3q5Lwdcty",
   "metadata": {
    "id": "rMA3q5Lwdcty"
   },
   "source": [
    "## uni-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sw7nx8qMeWaw",
   "metadata": {
    "id": "Sw7nx8qMeWaw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bagofwords(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xUQBPuWFdVvo",
   "metadata": {
    "id": "xUQBPuWFdVvo"
   },
   "source": [
    "## Bi-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3z4qhipIdros",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "3z4qhipIdros",
    "outputId": "95bf645c-81e7-463e-cbec-43fc9bdd6129"
   },
   "outputs": [],
   "source": [
    "bagofwords(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22Epy9R8dihU",
   "metadata": {
    "id": "22Epy9R8dihU"
   },
   "source": [
    "## Tri-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdZ9TR2Aee-h",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdZ9TR2Aee-h",
    "outputId": "7ee1b567-e4a1-4500-91f1-bcd5aaf54c39"
   },
   "outputs": [],
   "source": [
    "bagofwords(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qVwgT2aObnpY",
   "metadata": {
    "id": "qVwgT2aObnpY"
   },
   "source": [
    "## TF-IDF fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "G4TJd49Mb7Bm",
   "metadata": {
    "id": "G4TJd49Mb7Bm"
   },
   "outputs": [],
   "source": [
    " def TFIDFfunction(n,n1):\n",
    "  model = TfidfVectorizer(ngram_range=(n,n1))\n",
    "  x = model.fit_transform(X).toarray()\n",
    "  print(\"shape of X is \", np.shape(x))\n",
    "  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)\n",
    "  # test_size = 0.2               # splitting the data into 80 and 20 percent between the training and test set           \n",
    "                                              # to get the best results.                                                           \n",
    "  # random_state = 1         # resetting the  random seed\n",
    "  # print the lenghth of both test and train set to see if there equally split.\n",
    "  print(\"The length of X_train is \",len(X_train), \" and the length of y_train is \", len(y_train))  \n",
    "  print(\"The length of X_test is \",len(X_test), \" and the length of y_test is \", len(y_test))\n",
    "  Classifier_function(BernoulliNB(), X_train, y_train, X_test, y_test, \"Bernoulli NB\")\n",
    "# DecisionTreeClassifier()\n",
    "# GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lhfuNqn3BJXK",
   "metadata": {
    "id": "lhfuNqn3BJXK"
   },
   "source": [
    "# TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QT4agmJ3dZBw",
   "metadata": {
    "id": "QT4agmJ3dZBw"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4iDGDUiaZMiN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "id": "4iDGDUiaZMiN",
    "outputId": "f58fb966-6c04-44a0-affc-99dc29e9fd4b"
   },
   "outputs": [],
   "source": [
    "TFIDFfunction(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZhcjpIsXvVDL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "ZhcjpIsXvVDL",
    "outputId": "98c69274-23f9-426f-b42e-dc389cf65554"
   },
   "outputs": [],
   "source": [
    "TFIDFfunction(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nVB2tOKnvZyt",
   "metadata": {
    "id": "nVB2tOKnvZyt"
   },
   "outputs": [],
   "source": [
    "TFIDFfunction(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zK9mJKQqXJHp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zK9mJKQqXJHp",
    "outputId": "d4181b73-f6c0-4a77-a197-6eca855e9e93"
   },
   "outputs": [],
   "source": [
    "model = TfidfVectorizer(ngram_range=(1,1), max_features = 10000)\n",
    "X = model.fit_transform(lematized_model).toarray()\n",
    "print(\"shape of X is \", np.shape(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "# test_size = 0.2               # splitting the data into 80 and 20 percent between the training and test set           \n",
    "                                            # to get the best results.                                                           \n",
    "# random_state = 1         # resetting the  random seed\n",
    "# print the lenghth of both test and train set to see if there equally split.\n",
    "print(\"The length of X_train is \",len(X_train), \" and the length of y_train is \", len(y_train))  \n",
    "print(\"The length of X_test is \",len(X_test), \" and the length of y_test is \", len(y_test))\n",
    "\n",
    "\n",
    "# fitting the model\n",
    "automl = autosklearn.classification.AutoSklearnClassifier()\n",
    "automl.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "classfiersUsed = automl.cv_results_['param_classifier:__choice__']\n",
    "print(\"\\nclassifiers used: \", classfiersUsed)\n",
    "meanTestScore = automl.cv_results_['mean_test_score']\n",
    "print(\"\\nmean test score: \", meanTestScore)\n",
    "\n",
    "for i in range(len(classfiersUsed)):\n",
    "  print(classfiersUsed[i], \"==\", meanTestScore[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ILRbfVxUknYQ",
   "metadata": {
    "id": "ILRbfVxUknYQ"
   },
   "source": [
    "## Removing most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0sDBdy9Xj2EN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sDBdy9Xj2EN",
    "outputId": "34d49c39-4b51-498d-fe6c-5f86740781ce"
   },
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(DataFrame['tweet']).split()).value_counts()[:10]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LaE6EDGAmMWH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LaE6EDGAmMWH",
    "outputId": "e9b42081-fe49-4f31-d25b-90d26ddea989"
   },
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(DataFrame['tweet']).split()).value_counts()[:5]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qKWzAxP3j2Qo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qKWzAxP3j2Qo",
    "outputId": "79e5a39d-9161-4219-d1cc-9919fc88cc9b"
   },
   "outputs": [],
   "source": [
    "DataFrame['tweet'] = DataFrame['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "DataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3uyxs20fg-T7",
   "metadata": {
    "id": "3uyxs20fg-T7"
   },
   "source": [
    "## Removing the rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mFPrpQrvj2b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFPrpQrvj2b3",
    "outputId": "9ac5506f-875f-4282-e407-27a44909591f"
   },
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(DataFrame['tweet']).split()).value_counts()[-15:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hRfS1OoZnFXW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hRfS1OoZnFXW",
    "outputId": "af4b14cc-b4fd-4ab1-cff6-175595b9bdde"
   },
   "outputs": [],
   "source": [
    "DataFrame['tweet'] = DataFrame['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "DataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ef63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score  # performs cross validation. Helps in model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossvalscore(model, X, y, cv_val):  # function to perform cross validation with model X, y and cv_val as parameters\n",
    "    \"\"\"\n",
    "    The crossvalscore function prints the avarage coross validation accuracy of a model and its standard deveation.\n",
    "    \n",
    "    The first parameter model is the type of model to perform the cross validation on.\n",
    "    \n",
    "    The second parameter X is the features.\n",
    "    \n",
    "    The third parameter y is the labels.\n",
    "    \n",
    "    the foruth parameter cv_val is the number of times to cross validate the given model.\n",
    "    \n",
    "    The crossvalscore function returns the mean accuracy of the model.\n",
    "    \n",
    "    \"\"\"\n",
    "    score = cross_val_score(estimator = model, X = X, y = y, cv = cv_val, scoring = 'f1_micro')   # performs different tests to get best accurecy.\n",
    "    print(\"Accuracy: {:.2f} %\".format(score.mean()*100))  # accuracy printed.\n",
    "    print(\"Standard Deviation: {:.2f} %\".format(score.std()*100))  # standard deveation printed (std -avarage or std+ avarage )\n",
    "    return round(score.mean(),2)*100, round(score.std(),2)*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc0efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d0e7871",
   "metadata": {
    "id": "3uyxs20fg-T7"
   },
   "source": [
    "## autoskleanrn if neeed be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install build-essential swig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a768a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d96268",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbddca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autosklearn.classification # autosklearn classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8603fe",
   "metadata": {},
   "outputs": [],
   "source": [
    " def bagofwords(n,n1):\n",
    "  cv = CountVectorizer(ngram_range=(n,n1))\n",
    "  cv_X = cv.fit_transform(lematized_model).toarray()\n",
    "  cv_X_train, cv_X_test, cv_y_train, cv_y_test = train_test_split(cv_X, y, test_size = 0.2, random_state = 1)\n",
    "  # test_size = 0.2               # splitting the data into 80 and 20 percent between the training and test set           \n",
    "                                              # to get the best results.                                                           \n",
    "  # random_state = 1         # resetting the  random seed\n",
    "  # print the lenghth of both test and train set to see if there equally split.\n",
    "  print(\"The length of X_train is \",len(cv_X_train), \" and the length of y_train is \", len(cv_y_train))  \n",
    "  print(\"The length of X_test is \",len(cv_X_test), \" and the length of y_test is \", len(cv_y_test))\n",
    "  sklearn_automl_fun(cv_X_train, cv_y_train,  cv_X_test, cv_y_test)\n",
    "## Removing the rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c51b1",
   "metadata": {},
   "outputs": [],
   "source": [
    " def TFIDFfunction(n,n1):\n",
    "  model = TfidfVectorizer(ngram_range=(n,n1), max_features = 10000)\n",
    "  X = model.fit_transform(lematized_model).toarray()\n",
    "  print(\"shape of X is \", np.shape(X))\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "  # test_size = 0.2               # splitting the data into 80 and 20 percent between the training and test set           \n",
    "                                              # to get the best results.                                                           \n",
    "  # random_state = 1         # resetting the  random seed\n",
    "  # print the lenghth of both test and train set to see if there equally split.\n",
    "  print(\"The length of X_train is \",len(X_train), \" and the length of y_train is \", len(y_train))  \n",
    "  print(\"The length of X_test is \",len(X_test), \" and the length of y_test is \", len(y_test))\n",
    "  sklearn_automl_fun(X_train, y_train,  X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced9996e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10): \n",
    "    d1 = NewDf[NewDf['Labels']==0]\n",
    "\n",
    "    d1.head(3)\n",
    "\n",
    "    d2 = NewDf[NewDf['Labels']==1]\n",
    "\n",
    "    d2.head(3)\n",
    "\n",
    "    newdf1 = d1.head(500)\n",
    "\n",
    "    newdf1.shape[0]\n",
    "\n",
    "    newdf2 = d2.head(500)\n",
    "\n",
    "    newdf2.shape[0]\n",
    "\n",
    "    finaldf1 = pd.concat([newdf2, newdf1], ignore_index=True)\n",
    "\n",
    "    finaldf1.shape[0]\n",
    "\n",
    "    finaldf1.tail(5)\n",
    "\n",
    "    finaldf1.head(5)\n",
    "\n",
    "    finaldf1 = finaldf1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    finaldf1.head(5)\n",
    "\n",
    "    freq = sum(pd.Series(' '.join(finaldf1['Tweets']).split()).value_counts())\n",
    "    freq\n",
    "\n",
    "    ## Removing the rare words\n",
    "\n",
    "    # freq = pd.Series(' '.join(finaldf1['Tweets']).split()).value_counts()[-15:]\n",
    "    # freq\n",
    "\n",
    "    # finaldf1['Tweets'] = finaldf1['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "    # finaldf1.head()\n",
    "\n",
    "    ## Removing the most frequent words\n",
    "\n",
    "    freq = pd.Series(' '.join(finaldf1['Tweets']).split()).value_counts()[:55]\n",
    "    freq\n",
    "\n",
    "    sum(freq)\n",
    "\n",
    "    finaldf1['Tweets'] = finaldf1['Tweets'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "    finaldf1.head()\n",
    "\n",
    "    ## Removing words by occurance\n",
    "\n",
    "    '''\n",
    "    from collections import Counter\n",
    "    from itertools import chain\n",
    "\n",
    "    # split words into lists\n",
    "    v = finaldf1['Tweets'].str.split().tolist() # [s.split() for s in df['Col2'].tolist()]\n",
    "    # compute global word frequency\n",
    "    c = Counter(chain.from_iterable(v))\n",
    "    # filter, join, and re-assign\n",
    "    finaldf1['Tweets'] = [' '.join([j for j in i if c[j] > 4]) for i in v]\n",
    "    '''\n",
    "\n",
    "    freq = sum(pd.Series(' '.join(finaldf1['Tweets']).split()).value_counts())\n",
    "    freq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    finaldf1 = finaldf1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    ## Spliting X and y variables.\n",
    "\n",
    "    X = finaldf1.iloc[:, -1].values  # selecting the values for the X variable.\n",
    "\n",
    "    y = finaldf1.iloc[:, :-1].values # selecting the values for the Y variable. # done using .to_numpy and not \n",
    "                                                           # .iloc as .to_numpy creates a horizontal bar while .iloc creates a \n",
    "                                                           # horizontal bar which will not alighn with the x values.\n",
    "    bagofwords(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecd82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8081091930951425 - 0.8075070252910478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b036cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Detecting_toxic_language.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
